name: Run SQL and export CSV

on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 * * * *'   # каждые 60 минут (в начале часа, по UTC)

permissions:
  contents: write  # нужно, чтобы пушить изменения

jobs:
  run-query:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          # пины: sshtunnel 0.4.0 конфликтует с новыми paramiko
          pip install "psycopg2-binary==2.9.9" "sshtunnel==0.4.0" "paramiko==3.3.1"

      - name: Run queries and build CSVs
        env:
          # ---- Включаем SSH-туннели
          USE_SSH_DB1: "true"
          USE_SSH_DB2: "true"

          # ---- SSH для DB1 (может совпадать с SSH2_*)
          SSH1_HOST: ${{ secrets.SSH1_HOST }}
          SSH1_PORT: ${{ secrets.SSH1_PORT }}
          SSH1_USER: ${{ secrets.SSH1_USER }}
          SSH1_PRIVATE_KEY: ${{ secrets.SSH1_PRIVATE_KEY }}

          # ---- SSH для DB2 (может совпадать с SSH1_*)
          SSH2_HOST: ${{ secrets.SSH2_HOST }}
          SSH2_PORT: ${{ secrets.SSH2_PORT }}
          SSH2_USER: ${{ secrets.SSH2_USER }}
          SSH2_PRIVATE_KEY: ${{ secrets.SSH2_PRIVATE_KEY }}

          # ---- DB1 (как её видит bastion)
          DB1_HOST: ${{ secrets.DB1_HOST }}
          DB1_PORT: ${{ secrets.DB1_PORT }}
          DB1_NAME: ${{ secrets.DB1_NAME }}
          DB1_USER: ${{ secrets.DB1_USER }}
          DB1_PASSWORD: ${{ secrets.DB1_PASSWORD }}
          DB1_SSLMODE: ${{ secrets.DB1_SSLMODE }}
          DB1_STATEMENT_TIMEOUT_MS: ${{ secrets.DB1_STATEMENT_TIMEOUT_MS }}

          # ---- DB2 (как её видит bastion)
          DB2_HOST: ${{ secrets.DB2_HOST }}
          DB2_PORT: ${{ secrets.DB2_PORT }}
          DB2_NAME: ${{ secrets.DB2_NAME }}
          DB2_USER: ${{ secrets.DB2_USER }}
          DB2_PASSWORD: ${{ secrets.DB2_PASSWORD }}
          DB2_SSLMODE: ${{ secrets.DB2_SSLMODE }}
          DB2_STATEMENT_TIMEOUT_MS: ${{ secrets.DB2_STATEMENT_TIMEOUT_MS }}

          # ---- файлы и лимит
          SQL_FILE: data.sql
          USER_SQL_FILE: user_data.sql
          OUTPUT_CSV: raw_data.csv
          RESULT_CSV: result_data.csv
          TOP_N: 3000
        run: |
          python run_query.py

      - name: Commit CSVs to repo root
        run: |
          set -e
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Сначала коммитим, потом rebase/push
          git add raw_data.csv result_data.csv
          if git diff --staged --quiet; then
            echo "No changes — skipping commit/pull/push."
            exit 0
          fi

          git commit -m "Update raw_data.csv & result_data.csv [skip ci]"
          git pull --rebase --autostash origin "${{ github.ref_name }}"
          git push origin HEAD:"${{ github.ref_name }}"

      - name: Upload artifacts (optional)
        uses: actions/upload-artifact@v4
        with:
          name: csv_outputs
          path: |
            raw_data.csv
            result_data.csv
          if-no-files-found: error
